# Тесты на парсинг/генерацию файлов

### Cпособы проверки корректности файла:
* Проверять, что содержимое больше 0
* Проверять конкретные значения в файле
* Сравнивать побайтово
* Сравнение с эталонным файлом (approve подход)

Cпособы проверок могут зависеть от уровнея тестов.
Например на уровне интеграционных тестов мы проверяем все содержимое файла.
А на уровне UI тестов достаточно проверить, что
* Размер файла больше 0
* У файла верное разрешение и название
* Для генерации файла был вызван правильный метод

### Рассмотрим на конкретных примерах
Рассмотрим метод экспорта BookRepository.ExportBooksToXmlAsync
* Передается BookFilter
* Возвращает не xml, а string

<details>
<summary>1. Напишем тест на проверку непустого файла</summary>

   * Написать метод для создания BookFilter
   * Для создания книг используем контейнер для bookService и imageService 
   * В сетап вынести создание изображения 
   * Написать метод создания книги через BookBuilder 
   * Написать тест на проверку того, что ExportBooksToXmlAsync возвращает непустой файл

**Такая проверка будет полезна**
* Smoke тестировании, когда проверяется общая работоспособность системы;
* Если заранее неизвестны результаты выгрузки, например ИИ генерация данных;
* Если невозможно повлиять на набор выгружаемых данных, например при тестировании интеграции со сторонним сервисом;

</details>

<details>
<summary>2. Пишем тест на проверку конкретного значения в файле</summary>

   * Проверим русскоязычное название книги
   * Используем RussianBook из Helpers.Books
   * Конвертируем строку в XDocument
   * Проверяем значение элемента Book.Title, используя ассерты FluentAssertions HaveElement и HaveValue

**Такой способ пригодится, когда сценарий проверки направлен на изменение данных конкретного поля и нет необходимости проверять весь файл**

</details>

<details>
<summary>3. Напишем тест на проверку схемы файла</summary>

   * Если по фильтру не нашлось книги, то в выгрузке должны остаться элементы Books и ExportTime
   * Если проверять только наличие этих элементов, то тест всегда будет давать ложнополоожительный результат
   * Используем ассерты на строки и проверим, что в выгрузке есть элементы Books, ExportTime, но нет Book

</details>

<details>
<summary>4. Напишем тест на проверку количества выгруженных книг</summary>

   * Используем параметр limit в фильтре
   * Создалим в базе 5 книг, а лимит в фильтре укажем 4
   * Проверим количество элементов Book в выгрузке с помощью ассерта HaveElement("Book", Exactly.Times(4))
   * Либо можно использовать Regex("<Book>").Matches(xmlResult).Count

**Не нужно всегда сравнивать весь файл целиком. Когда сценарий проверки предполшагает изменение конкретного значения, лучше проверять только его. Это упросит чтение теста, поддержку, скорость прохождения, а также сделает тесты стабильнее**

</details>

<details>
<summary>5. Напишем тест на сравнение всего файла</summary>

   * Создаем XDocument с ожидаемой схемой
   * Сравниваем ожидаемый XDocument с полученным с помощью ассерта BeEquivalentTo()

*Если в выгрузке только одна книга, то проблемы с созданием XDocument в коде теста нет. Но для большших файлов или файлов, которые мы не можем сгенерировать из кода тестов, лучше подойдет подход Approval Tests.
Этот подход заключается в том, что тест сравнивает результаты работы системы, в нашем случае файлы, с эталонным, заранее определенным результатом. 
То есть мы будем сравнивать файл, который отдает нам система с эталонным файлом, который заранее подготовим и сохраним в нашем тестовом проекте.*

</details>

<details>
<summary>6. Напишем approval test</summary>

   * Все данные в тесте должны быть статичны, так как будут сравниваться с эталоном
   * Написать цикл в котором будут создаваться книги.
   * Используем "Default name" + счетчик цикла для названия книги и "Default author" + счетчик цикла для автора.
   * Получить результат выгрузки. В данный момент мы считаем, что результат валидный, поэтому используем его в качестве эталона.
   * Скоппировать результат выгрузки и добавить его в файл Integration\Files\exportBooks.xml
   * В тесте сравниваем результат выгрузки и эталон с помощью ассерта Should().BeEquivalentTo()
   * Тест упал, потому что ExportTime не статичный
   * Для того, чтобы тест проходил, в эталонном файле подменяем ExportTime на DateTime.Now

**Даты и время – это наиболее нестабильные данные, которые часто приводят к ложным падениям тестов.**
Если случится задержка перед вызовом метода, то значение, которое мы будем ожидать станет отличаться от фактического и тест упадет.
Также, часто расхождения могут случаться на стыке минут\часов\дней\месяцев или лет.
Чтобы тесты, в которых необходимо проверять даты, были стабильными, можно использовать разные методы.
* Использовать константу времени, так чтобы в данных всегда была одна и та же дата. Например указывать в базе нужную дату при создании объекта, а не текущую.
* Проверять только значимую часть даты. Например, если функциональность завязана на годах, то проверять только год. Так падений на стыке времени будет меньше (будут случаться не чаще раза в год)

</details>

### Итог
Мы рассмотрели несколько подходов в написании тестов на документы. Каждый из них применим для разных проверок и может комбинироваться. Отличительным преимуществом интеграционных тестов является их быстродействие, поэтому важно не перегружать логику тестов и проверять только необходимое. Например, нет смысла каждый раз проверять весь файл целиком. Намного быстрее будет написать несколько коротких тестов на проверку одного значения, которое меняется в конкретном кейсе.
Также важно не забывать об основных правилах написания тестов и стабильности данных, которые используются в них. 
